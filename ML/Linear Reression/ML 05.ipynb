{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 5-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification<br>\n",
    "\n",
    "Spam 메일 or Ham 메일을 분류 <br>\n",
    "facebook feed : 흥미있는 것만 들어옴 <br>\n",
    "Credit Card : 기존에 썻던 거랑 다르면 이상하게 생각하는 기능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어 <br>\n",
    "시험에 합격되는것을 0(불합격)과 1(합격)로 하였을 때 Linear regression 으로 하면 여러가지 문제가 있다.<br>\n",
    "Hypothesis도 기존에 하던 H(x) = Wx+b 로하면 정확히 0이나 1로 값이 안나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis 의 H(x) 를 g(z)로 변경<br>\n",
    "g(z) = 1/(1+e**-z)<br>\n",
    "g(z)를 <b>sigmoid</b> 라고 부른다. <br>\n",
    "or <br>\n",
    "logistic function 이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "새로운 Hypothesis <br>\n",
    "z = Wx <br>\n",
    "H(x) = g(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 5-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "변경된 H(x)로 cost 그래프를 보면 매끄럽지않은걸 볼 수 있다.<br>\n",
    "처음 시작하는 부분에 따라서 최솟점이 달라질 수가 있다.<br>\n",
    "기존에 썼던 것 처럼 gradient를 사용할 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C(H(x),y)  = -log(H(x)) : y=1 이라고 하면 <br>\n",
    "H(x) 의 값이 1 이면 (답을 맞춤) -> cost(1) = 0<br>\n",
    "H(x) 의 값이 0 이면 (답을 틀림) -> cost = 무한값 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C(H(x),y) = -log(1-H(x)) : y=0 이라고 하면 <Br>\n",
    "H(x) = 0(답을 맞춤) -> cost = 0<br>\n",
    "H(x) = 1(답을 틀림) -> cost = 무한값  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이러한 두개를 합치면 기존에 했던 모양이 되어 gradient를 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C(H(x),y) = -ylog(H(x))-(1-y)log(1-H(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y = 1 이면 <br>\n",
    "C = -log(H(x))<br>\n",
    "y = 0 이면 <br>\n",
    "C = -log(1-H(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1,2],[2,3],[3,1],[4,3],[5,3],[6,2]]\n",
    "y_data = [[0],[0],[0],[1],[1],[1]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None,2])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,1]) # shape 주의\n",
    "w = tf.Variable(tf.random_normal([2,1]),name='weight') # x 가 두개씩 있고 y는 한개\n",
    "b = tf.Variable(tf.random_normal([1]),name='bias') # 항상 나가는 값의 크기\n",
    "\n",
    "hypothesis= tf.sigmoid(tf.matmul(X,w)+b)\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis)+ (1-Y)* tf.log(1-hypothesis))\n",
    "#C(H(x),y) = -ylog(H(x))-(1-y)log(1-H(x))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tf.cast(hypothesis > 0.5 , dtype=tf.float32) # 이것이 True , false로 나옴\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9646962\n",
      "200 0.41151157\n",
      "400 0.3944919\n",
      "600 0.38000843\n",
      "800 0.36705872\n",
      "1000 0.35515693\n",
      "1200 0.34404957\n",
      "1400 0.3335944\n",
      "1600 0.32370454\n",
      "1800 0.31432214\n",
      "2000 0.305405\n",
      "2200 0.29691985\n",
      "2400 0.28883836\n",
      "2600 0.28113586\n",
      "2800 0.2737898\n",
      "3000 0.26677957\n",
      "3200 0.26008585\n",
      "3400 0.25369057\n",
      "3600 0.24757689\n",
      "3800 0.24172892\n",
      "4000 0.23613174\n",
      "4200 0.23077135\n",
      "4400 0.22563462\n",
      "4600 0.22070919\n",
      "4800 0.21598361\n",
      "5000 0.21144694\n",
      "5200 0.20708905\n",
      "5400 0.20290034\n",
      "5600 0.19887199\n",
      "5800 0.19499557\n",
      "6000 0.19126318\n",
      "6200 0.18766743\n",
      "6400 0.18420146\n",
      "6600 0.18085869\n",
      "6800 0.17763317\n",
      "7000 0.174519\n",
      "7200 0.17151074\n",
      "7400 0.16860344\n",
      "7600 0.16579235\n",
      "7800 0.16307275\n",
      "8000 0.16044062\n",
      "8200 0.15789191\n",
      "8400 0.15542284\n",
      "8600 0.1530298\n",
      "8800 0.1507095\n",
      "9000 0.14845873\n",
      "9200 0.14627452\n",
      "9400 0.14415406\n",
      "9600 0.14209455\n",
      "9800 0.14009361\n",
      "10000 0.13814873\n",
      "\n",
      "Hypothesis :  [[0.02611557]\n",
      " [0.15206179]\n",
      " [0.28191018]\n",
      " [0.79207504]\n",
      " [0.9461132 ]\n",
      " [0.982385  ]] \n",
      "Correct (Y):  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost,train], feed_dict={X: x_data, Y:y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, cost_val)\n",
    "    h, c, a = sess.run([hypothesis,predicted,accuracy], feed_dict={X:x_data,Y:y_data})\n",
    "    print(\"\\nHypothesis : \",h,\"\\nCorrect (Y): \", c ,\"\\nAccuracy: \",a)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "실제 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('data-03-diabetes.csv', delimiter=',',dtype=np.float32)\n",
    "# 무수한 값과 마지막에 0이면 당뇨병 X / 1이면 당뇨병 O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = xy[:,0:-1]\n",
    "y_data = xy[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None,8])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,1]) # shape 주의\n",
    "w = tf.Variable(tf.random_normal([8,1]),name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]),name='bias')\n",
    "\n",
    "hypothesis= tf.sigmoid(tf.matmul(X,w)+b)\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis)+ (1-Y)* tf.log(1-hypothesis))\n",
    "#C(H(x),y) = -ylog(H(x))-(1-y)log(1-H(x))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5 , dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.664218\n",
      "200 1.1658957\n",
      "400 0.9282303\n",
      "600 0.83249557\n",
      "800 0.7826365\n",
      "1000 0.7461157\n",
      "1200 0.71540284\n",
      "1400 0.68866193\n",
      "1600 0.6651211\n",
      "1800 0.6442327\n",
      "2000 0.62554586\n",
      "2200 0.60868686\n",
      "2400 0.59335065\n",
      "2600 0.5792906\n",
      "2800 0.56630874\n",
      "3000 0.5542457\n",
      "3200 0.54297364\n",
      "3400 0.53238875\n",
      "3600 0.5224066\n",
      "3800 0.51295745\n",
      "4000 0.50398374\n",
      "4200 0.4954372\n",
      "4400 0.4872768\n",
      "4600 0.4794678\n",
      "4800 0.4719803\n",
      "5000 0.4647882\n",
      "5200 0.45786887\n",
      "5400 0.4512025\n",
      "5600 0.44477117\n",
      "5800 0.43855935\n",
      "6000 0.43255293\n",
      "6200 0.42673925\n",
      "6400 0.42110693\n",
      "6600 0.41564566\n",
      "6800 0.4103459\n",
      "7000 0.40519917\n",
      "7200 0.40019742\n",
      "7400 0.39533356\n",
      "7600 0.39060083\n",
      "7800 0.3859931\n",
      "8000 0.3815045\n",
      "8200 0.37712988\n",
      "8400 0.3728642\n",
      "8600 0.36870286\n",
      "8800 0.36464152\n",
      "9000 0.36067608\n",
      "9200 0.35680288\n",
      "9400 0.35301816\n",
      "9600 0.34931874\n",
      "9800 0.3457013\n",
      "10000 0.3421629\n",
      "\n",
      "Hypothesis :  [[0.780158  ]\n",
      " [0.24859631]\n",
      " [0.719645  ]\n",
      " [0.07262695]\n",
      " [0.3238148 ]\n",
      " [0.652957  ]\n",
      " [0.4492848 ]\n",
      " [0.68060994]] \n",
      "Correct (Y):  [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    feed = {X: x_data , Y:y_data}\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict=feed)\n",
    "        if step % 200 == 0:\n",
    "            print(step, sess.run(cost, feed_dict=feed))\n",
    "    h, c, a = sess.run([hypothesis,predicted,accuracy], feed_dict=feed)\n",
    "    print(\"\\nHypothesis : \",h,\"\\nCorrect (Y): \", c ,\"\\nAccuracy: \",a)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
