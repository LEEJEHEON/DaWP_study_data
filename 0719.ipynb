{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab, Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab(dicpath = 'D:\\\\mecab\\\\mecab-ko-dic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./719/stopwordlist.txt') as f1:\n",
    "    stopwordlist = f1.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이다',\n",
       " '기다',\n",
       " '있다',\n",
       " '진짜',\n",
       " '지네',\n",
       " '입니다',\n",
       " '하나',\n",
       " '니다',\n",
       " '제가',\n",
       " '이건',\n",
       " '해주다',\n",
       " '하네',\n",
       " '이랑',\n",
       " '오늘',\n",
       " '한번',\n",
       " '요즘',\n",
       " '결국',\n",
       " '때문',\n",
       " '정도',\n",
       " '같다',\n",
       " '어떻',\n",
       " '겁니다',\n",
       " '뭐라다',\n",
       " '라다',\n",
       " '생각',\n",
       " '저렇',\n",
       " '하고나서다',\n",
       " '하던',\n",
       " '이렇',\n",
       " '어떻다',\n",
       " '어떻하',\n",
       " '어떻하다',\n",
       " '어떡하다',\n",
       " '아니다',\n",
       " '그렇다',\n",
       " '이렇다',\n",
       " '가요',\n",
       " '어떻다',\n",
       " '라그나',\n",
       " '내요',\n",
       " '주세요',\n",
       " '지네',\n",
       " '가즈',\n",
       " '그라',\n",
       " '비티',\n",
       " '이러다',\n",
       " '저러다',\n",
       " '그러다',\n",
       " '이렇다',\n",
       " '저렇다',\n",
       " '그렇',\n",
       " 'ㅣㅆ다',\n",
       " '역시',\n",
       " '반면',\n",
       " '어제',\n",
       " '얼마',\n",
       " '대부분',\n",
       " '조금',\n",
       " '애초',\n",
       " '이제',\n",
       " '그때',\n",
       " '까지',\n",
       " '짜리',\n",
       " '이번',\n",
       " '요번',\n",
       " '사람',\n",
       " '나다',\n",
       " '희다',\n",
       " '없음',\n",
       " '같다',\n",
       " '없다',\n",
       " '동안',\n",
       " '이상',\n",
       " '이하',\n",
       " '저번',\n",
       " '안녕',\n",
       " '약간',\n",
       " '나',\n",
       " '이전',\n",
       " '해서',\n",
       " '해도',\n",
       " '니들',\n",
       " '인해',\n",
       " '하다',\n",
       " '것',\n",
       " '들',\n",
       " '그',\n",
       " '되다',\n",
       " '수',\n",
       " '허다',\n",
       " '보',\n",
       " '않다',\n",
       " '주',\n",
       " '아니',\n",
       " '등',\n",
       " '우리',\n",
       " '때',\n",
       " '년',\n",
       " '가',\n",
       " '한',\n",
       " '지',\n",
       " '대하다',\n",
       " '오',\n",
       " '말',\n",
       " '일',\n",
       " '위하다',\n",
       " '그것',\n",
       " '두',\n",
       " '말하다',\n",
       " '알',\n",
       " '그러나',\n",
       " '받다',\n",
       " '그런',\n",
       " '또',\n",
       " '문제',\n",
       " '더',\n",
       " '사회',\n",
       " '많다',\n",
       " '그리고',\n",
       " '크다',\n",
       " '중',\n",
       " '가지다',\n",
       " '씨',\n",
       " '만들다',\n",
       " '지금',\n",
       " '속',\n",
       " '집',\n",
       " '적',\n",
       " '월',\n",
       " '자신',\n",
       " '어떤',\n",
       " '내',\n",
       " '경우',\n",
       " '명',\n",
       " '시간',\n",
       " '그녀',\n",
       " '다시',\n",
       " '이런',\n",
       " '앞',\n",
       " '보이',\n",
       " '번',\n",
       " '다른',\n",
       " '여자',\n",
       " '개',\n",
       " '전',\n",
       " '사실',\n",
       " '점',\n",
       " '싶다',\n",
       " '정도',\n",
       " '좀',\n",
       " '원',\n",
       " '잘',\n",
       " '소리',\n",
       " '놓다',\n",
       " '입',\n",
       " '드리',\n",
       " '어떡',\n",
       " '어찌',\n",
       " 'ㅆ',\n",
       " 'ㅣ',\n",
       " '가다',\n",
       " '까지다',\n",
       " '놓다',\n",
       " '드리다',\n",
       " '들다',\n",
       " '떡',\n",
       " '라',\n",
       " '링',\n",
       " '만들다',\n",
       " '비다',\n",
       " '알다',\n",
       " '만하다',\n",
       " '오다',\n",
       " '위하다',\n",
       " '이다다',\n",
       " '인하다',\n",
       " '주다',\n",
       " '통하다',\n",
       " '티',\n",
       " '포',\n",
       " '다다',\n",
       " '끄다',\n",
       " '나오다',\n",
       " '싶다',\n",
       " '이르다',\n",
       " '자다',\n",
       " '줄다',\n",
       " '지다',\n",
       " '짜다',\n",
       " '보다',\n",
       " '돼다',\n",
       " '아무것',\n",
       " '넘다',\n",
       " '건지다',\n",
       " '되어다',\n",
       " '써다',\n",
       " '졸다',\n",
       " '말다',\n",
       " '맵다',\n",
       " '시다',\n",
       " '그르다',\n",
       " '건지',\n",
       " '그러',\n",
       " '그르',\n",
       " '끄',\n",
       " '넘',\n",
       " '돼',\n",
       " '되',\n",
       " '받',\n",
       " '쓰',\n",
       " '이르',\n",
       " '이러',\n",
       " '인하',\n",
       " '저러',\n",
       " '졸',\n",
       " '줄',\n",
       " '짜',\n",
       " '하',\n",
       " '있',\n",
       " '치',\n",
       " '쓰다',\n",
       " 'ㅣㅆ',\n",
       " '걸다',\n",
       " '까다',\n",
       " '내다',\n",
       " '미남',\n",
       " '재',\n",
       " '매다',\n",
       " '스러워',\n",
       " '너무',\n",
       " '다',\n",
       " '스럽다',\n",
       " '며칠']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwordlist = [stop.replace('\\n','') for stop in stopwordlist]\n",
    "stopwordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8618, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"./719/FLO_playstore.csv\",engine='python', encoding='utf-8')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('재생', 'NNG'),\n",
       " ('목록', 'NNG'),\n",
       " ('에서', 'JKB'),\n",
       " ('선택', 'NNG'),\n",
       " ('재생', 'NNG'),\n",
       " ('할', 'XSV+ETM'),\n",
       " ('수', 'NNB'),\n",
       " ('있', 'VV'),\n",
       " ('게', 'EC'),\n",
       " ('해', 'VV+EC'),\n",
       " ('주', 'VX'),\n",
       " ('세요', 'EP+EF'),\n",
       " ('.', 'SF'),\n",
       " ('재생', 'NNG'),\n",
       " ('목록', 'NNG'),\n",
       " ('편집', 'NNG'),\n",
       " ('도', 'JX'),\n",
       " ('여러', 'MM'),\n",
       " ('개', 'NNBC'),\n",
       " ('선택', 'NNG'),\n",
       " ('해서', 'XSV+EC'),\n",
       " ('위아래', 'NNG'),\n",
       " ('로', 'JKB'),\n",
       " ('옮길', 'VV+ETM'),\n",
       " ('수', 'NNB'),\n",
       " ('있', 'VV'),\n",
       " ('는', 'ETM'),\n",
       " ('기능', 'NNG'),\n",
       " ('도', 'JX'),\n",
       " ('추가', 'NNG'),\n",
       " ('해', 'XSV+EC'),\n",
       " ('주', 'VX'),\n",
       " ('세요', 'EP+EF'),\n",
       " ('.', 'SF'),\n",
       " ('지니', 'NNP'),\n",
       " ('로', 'JKB'),\n",
       " ('만', 'JX'),\n",
       " ('듣', 'VV'),\n",
       " ('다가', 'EC'),\n",
       " ('처음', 'MAG'),\n",
       " ('넘어왔', 'VV+EP'),\n",
       " ('는데', 'EC'),\n",
       " ('안', 'MAG'),\n",
       " ('되', 'VV'),\n",
       " ('는', 'ETM'),\n",
       " ('기능', 'NNG'),\n",
       " ('이', 'JKS'),\n",
       " ('넘', 'MAG'),\n",
       " ('많', 'VA'),\n",
       " ('네요', 'EF'),\n",
       " ('ㅠㅠ', 'UNKNOWN'),\n",
       " ('켑쳐해서', 'UNKNOWN'),\n",
       " ('노래', 'NNG'),\n",
       " ('추가', 'NNG'),\n",
       " ('하', 'XSV'),\n",
       " ('는', 'ETM'),\n",
       " ('건', 'NNB+JX'),\n",
       " ('노래', 'NNG'),\n",
       " ('를', 'JKO'),\n",
       " ('잘못', 'MAG'),\n",
       " ('추가', 'NNG'),\n",
       " ('한', 'XSV+ETM'),\n",
       " ('경우', 'NNG'),\n",
       " ('가', 'JKS'),\n",
       " ('있', 'VV'),\n",
       " ('긴', 'ETN+JX'),\n",
       " ('했', 'VX+EP'),\n",
       " ('지만', 'EC'),\n",
       " ('나름', 'NNB'),\n",
       " ('편리', 'NNG'),\n",
       " ('한', 'XSA+ETM'),\n",
       " ('기능', 'NNG'),\n",
       " ('이', 'VCP'),\n",
       " ('었', 'EP'),\n",
       " ('습니다', 'EF'),\n",
       " ('.', 'SF'),\n",
       " ('빠른', 'VA+ETM'),\n",
       " ('개선', 'NNG'),\n",
       " ('으로', 'JKB'),\n",
       " ('편의', 'NNG'),\n",
       " ('성', 'XSN'),\n",
       " ('있', 'VV'),\n",
       " ('는', 'ETM'),\n",
       " ('앱', 'NNG'),\n",
       " ('이', 'JKS'),\n",
       " ('되', 'VV'),\n",
       " ('길', 'ETN+JKO'),\n",
       " ('바랄게', 'VV+ETM+NNB+JKS'),\n",
       " ('요', 'JX'),\n",
       " ('캡쳐', 'NNP'),\n",
       " ('리스트', 'NNG'),\n",
       " ('에서', 'JKB'),\n",
       " ('이사', 'NNG'),\n",
       " ('할', 'XSV+ETM'),\n",
       " ('때', 'NNG'),\n",
       " ('잘못', 'MAG'),\n",
       " ('인식', 'NNG'),\n",
       " ('한', 'XSV+ETM'),\n",
       " ('곡', 'NNG'),\n",
       " ('들', 'XSN'),\n",
       " ('이', 'VCP'),\n",
       " ('예요', 'EF'),\n",
       " ('!', 'SF'),\n",
       " ('김', 'NNG'),\n",
       " ('하', 'XSV'),\n",
       " ('온', 'EC+VX+ETM'),\n",
       " ('-', 'SY'),\n",
       " ('OOOOOOL', 'SL'),\n",
       " ('/', 'SC'),\n",
       " ('kacey', 'SL'),\n",
       " ('musgraves', 'SL'),\n",
       " ('-', 'SY'),\n",
       " ('all', 'SL'),\n",
       " ('is', 'SL'),\n",
       " ('found', 'SL'),\n",
       " ('(', 'SSO'),\n",
       " ('kacey', 'SL'),\n",
       " ('musgraves', 'SL'),\n",
       " ('ver', 'SL'),\n",
       " ('.', 'SF'),\n",
       " (')', 'SY'),\n",
       " ('/', 'SC'),\n",
       " ('Billie', 'SL'),\n",
       " ('eilish', 'SL'),\n",
       " ('-', 'SY'),\n",
       " ('bad', 'SL'),\n",
       " ('guy', 'SL'),\n",
       " ('/', 'SC'),\n",
       " ('Billie', 'SL'),\n",
       " ('eilish', 'SL'),\n",
       " ('-', 'SY'),\n",
       " ('xanny', 'SL'),\n",
       " ('/', 'SC'),\n",
       " ('Billie', 'SL'),\n",
       " ('eilish', 'SL'),\n",
       " ('-', 'SY'),\n",
       " ('wish', 'SL'),\n",
       " ('you', 'SL'),\n",
       " ('were', 'SL'),\n",
       " ('gay', 'SL'),\n",
       " ('/', 'SC'),\n",
       " ('Billie', 'SL'),\n",
       " ('eilish', 'SL'),\n",
       " ('-', 'SY'),\n",
       " ('bury', 'SL'),\n",
       " ('a', 'SL'),\n",
       " ('friend', 'SL'),\n",
       " ('/', 'SC'),\n",
       " ('Billie', 'SL'),\n",
       " ('eilish', 'SL'),\n",
       " ('-', 'SY'),\n",
       " ('everything', 'SL'),\n",
       " ('I', 'SL'),\n",
       " ('wanted', 'SL'),\n",
       " ('/', 'SC'),\n",
       " ('정동원', 'NNP'),\n",
       " ('-', 'SY'),\n",
       " ('사랑', 'NNG'),\n",
       " ('은', 'JX'),\n",
       " ('눈물', 'NNG'),\n",
       " ('의', 'JKG'),\n",
       " ('씨앗', 'NNG'),\n",
       " ('/', 'SC'),\n",
       " ('정동원', 'NNP'),\n",
       " ('-', 'SY'),\n",
       " ('눈물비', 'NNG'),\n",
       " ('/', 'SC'),\n",
       " ('정동원', 'NNP'),\n",
       " ('-', 'SY'),\n",
       " ('청춘', 'NNG'),\n",
       " ('/', 'SC'),\n",
       " ('정동원', 'NNP'),\n",
       " ('-', 'SY'),\n",
       " ('우수', 'NNG'),\n",
       " ('/', 'SC'),\n",
       " ('정동원', 'NNP'),\n",
       " ('-', 'SY'),\n",
       " ('누가', 'NP+JKS'),\n",
       " ('울', 'VV'),\n",
       " ('어', 'EC')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#단어 -> 토큰\n",
    "# 형태소 단위 \n",
    "# mecab 사용\n",
    "sample_text = df['user_text'].values[0]\n",
    "mecab.pos(sample_text)\n",
    "# NNG , NNP , VA, VV (일반명사, 고유명사, 형용사, 동사)\n",
    "# 위의 tag에 해당하는 단어만 포함된 list를 뽑기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_text'] = df['user_text'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_corpus_df = df.loc[df['user_text'].apply(len)>10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('재', 'XPN')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mecab.pos(sample_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = []\n",
    "for (string, code) in mecab.pos(sample_text):\n",
    "    if code =='NNG' or code =='NNP' :\n",
    "        list_1.append(string)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectors=filtered_corpus_df['user_text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    taglist = ['NNG', 'NNP']\n",
    "    result_words = [word for (word,tag) in mecab.pos(text) if tag in taglist]\n",
    "    return result_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['르'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=tokenizer , stop_words = stopwordlist)\n",
    "X_matrix = vectorizer.fit_transform(text_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ㄱ</th>\n",
       "      <th>ㄴ</th>\n",
       "      <th>ㄷ</th>\n",
       "      <th>ㄹ</th>\n",
       "      <th>ㅁ</th>\n",
       "      <th>ㅂ</th>\n",
       "      <th>ㅅ</th>\n",
       "      <th>ㅈ</th>\n",
       "      <th>我</th>\n",
       "      <th>里</th>\n",
       "      <th>...</th>\n",
       "      <th>히스토리</th>\n",
       "      <th>히어로</th>\n",
       "      <th>히트</th>\n",
       "      <th>힌</th>\n",
       "      <th>힐링</th>\n",
       "      <th>힘</th>\n",
       "      <th>힙</th>\n",
       "      <th>힙합</th>\n",
       "      <th>힝</th>\n",
       "      <th>힣</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4363 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ㄱ  ㄴ  ㄷ  ㄹ  ㅁ  ㅂ  ㅅ  ㅈ  我  里  ...  히스토리  히어로  히트  힌  힐링  힘  힙  힙합  힝  힣\n",
       "0  0  0  0  0  0  0  0  0  0  0  ...     0    0   0  0   0  0  0   0  0  0\n",
       "1  0  0  0  0  0  0  0  0  0  0  ...     0    0   0  0   0  1  0   0  0  0\n",
       "2  0  0  0  0  0  0  0  0  0  0  ...     0    0   0  0   0  0  0   0  0  0\n",
       "3  0  0  0  0  0  0  0  0  0  0  ...     0    0   0  0   0  0  0   0  0  0\n",
       "4  0  0  0  0  0  0  0  0  0  0  ...     0    0   0  0   0  0  0   0  0  0\n",
       "\n",
       "[5 rows x 4363 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list= vectorizer.get_feature_names()\n",
    "document_term_matrix = pd.DataFrame(X_matrix.toarray(), columns=word_list)\n",
    "document_term_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "노래      3118\n",
       "재생      1960\n",
       "곡       1734\n",
       "음악      1392\n",
       "사용      1314\n",
       "앱       1307\n",
       "기능       956\n",
       "플        940\n",
       "이용       923\n",
       "리스트      851\n",
       "불편       762\n",
       "가사       697\n",
       "멜론       684\n",
       "업데이트     680\n",
       "목록       662\n",
       "플로       656\n",
       "플레이      610\n",
       "추가       608\n",
       "무료       552\n",
       "결제       542\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_term_matrix.sum(axis=0).sort_values(ascending= False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('재생', 'Noun'),\n",
       " ('목록', 'Noun'),\n",
       " ('에서', 'Josa'),\n",
       " ('선택', 'Noun'),\n",
       " ('재생', 'Noun'),\n",
       " ('하다', 'Verb'),\n",
       " ('수', 'Noun'),\n",
       " ('있다', 'Adjective'),\n",
       " ('해주다', 'Verb'),\n",
       " ('.', 'Punctuation'),\n",
       " ('재생', 'Noun'),\n",
       " ('목록', 'Noun'),\n",
       " ('편집', 'Noun'),\n",
       " ('도', 'Josa'),\n",
       " ('여러', 'Modifier'),\n",
       " ('개', 'Noun'),\n",
       " ('선택', 'Noun'),\n",
       " ('하다', 'Verb'),\n",
       " ('위아래', 'Noun'),\n",
       " ('로', 'Josa'),\n",
       " ('옮기다', 'Verb'),\n",
       " ('수', 'Noun'),\n",
       " ('있다', 'Adjective'),\n",
       " ('기능', 'Noun'),\n",
       " ('도', 'Josa'),\n",
       " ('추가', 'Noun'),\n",
       " ('해주다', 'Verb'),\n",
       " ('.', 'Punctuation'),\n",
       " ('지니', 'Noun'),\n",
       " ('로만', 'Noun'),\n",
       " ('듣다', 'Verb'),\n",
       " ('처음', 'Noun'),\n",
       " ('넘어오다', 'Verb'),\n",
       " ('안되다', 'Adjective'),\n",
       " ('기능', 'Noun'),\n",
       " ('이', 'Josa'),\n",
       " ('넘다', 'Verb'),\n",
       " ('많다', 'Adjective'),\n",
       " ('ㅠㅠ', 'KoreanParticle'),\n",
       " ('켑쳐해', 'Noun'),\n",
       " ('서', 'Josa'),\n",
       " ('노래', 'Noun'),\n",
       " ('추가', 'Noun'),\n",
       " ('하다', 'Verb'),\n",
       " ('노래', 'Noun'),\n",
       " ('를', 'Josa'),\n",
       " ('잘못', 'Noun'),\n",
       " ('추가', 'Noun'),\n",
       " ('한', 'Josa'),\n",
       " ('경우', 'Noun'),\n",
       " ('가', 'Josa'),\n",
       " ('있다', 'Adjective'),\n",
       " ('하다', 'Verb'),\n",
       " ('나름', 'Noun'),\n",
       " ('편리하다', 'Adjective'),\n",
       " ('기능', 'Noun'),\n",
       " ('이다', 'Verb'),\n",
       " ('.', 'Punctuation'),\n",
       " ('빠르다', 'Adjective'),\n",
       " ('개선', 'Noun'),\n",
       " ('으로', 'Josa'),\n",
       " ('편의', 'Noun'),\n",
       " ('성', 'Suffix'),\n",
       " ('있다', 'Adjective'),\n",
       " ('앱', 'Noun'),\n",
       " ('이', 'Josa'),\n",
       " ('되다', 'Verb'),\n",
       " ('바라다', 'Verb'),\n",
       " ('캡쳐', 'Noun'),\n",
       " ('리스트', 'Noun'),\n",
       " ('에서', 'Josa'),\n",
       " ('이사', 'Noun'),\n",
       " ('하다', 'Verb'),\n",
       " ('때', 'Noun'),\n",
       " ('잘못', 'Noun'),\n",
       " ('인식', 'Noun'),\n",
       " ('한', 'Josa'),\n",
       " ('곡', 'Noun'),\n",
       " ('들이다', 'Verb'),\n",
       " ('!', 'Punctuation'),\n",
       " ('기다', 'Verb'),\n",
       " ('온', 'Noun'),\n",
       " ('-', 'Punctuation'),\n",
       " ('OOOOOOL', 'Alpha'),\n",
       " ('/', 'Punctuation'),\n",
       " ('kacey', 'Alpha'),\n",
       " ('musgraves', 'Alpha'),\n",
       " ('-', 'Punctuation'),\n",
       " ('all', 'Alpha'),\n",
       " ('is', 'Alpha'),\n",
       " ('found', 'Alpha'),\n",
       " ('(', 'Punctuation'),\n",
       " ('kacey', 'Alpha'),\n",
       " ('musgraves', 'Alpha'),\n",
       " ('ver', 'Alpha'),\n",
       " ('.)', 'Punctuation'),\n",
       " ('/', 'Punctuation'),\n",
       " ('Billie', 'Alpha'),\n",
       " ('eilish', 'Alpha'),\n",
       " ('-', 'Punctuation'),\n",
       " ('bad', 'Alpha'),\n",
       " ('guy', 'Alpha'),\n",
       " ('/', 'Punctuation'),\n",
       " ('Billie', 'Alpha'),\n",
       " ('eilish', 'Alpha'),\n",
       " ('-', 'Punctuation'),\n",
       " ('xanny', 'Alpha'),\n",
       " ('/', 'Punctuation'),\n",
       " ('Billie', 'Alpha'),\n",
       " ('eilish', 'Alpha'),\n",
       " ('-', 'Punctuation'),\n",
       " ('wish', 'Alpha'),\n",
       " ('you', 'Alpha'),\n",
       " ('were', 'Alpha'),\n",
       " ('gay', 'Alpha'),\n",
       " ('/', 'Punctuation'),\n",
       " ('Billie', 'Alpha'),\n",
       " ('eilish', 'Alpha'),\n",
       " ('-', 'Punctuation'),\n",
       " ('bury', 'Alpha'),\n",
       " ('a', 'Alpha'),\n",
       " ('friend', 'Alpha'),\n",
       " ('/', 'Punctuation'),\n",
       " ('Billie', 'Alpha'),\n",
       " ('eilish', 'Alpha'),\n",
       " ('-', 'Punctuation'),\n",
       " ('everything', 'Alpha'),\n",
       " ('I', 'Alpha'),\n",
       " ('wanted', 'Alpha'),\n",
       " ('/', 'Punctuation'),\n",
       " ('정동원', 'Noun'),\n",
       " ('-', 'Punctuation'),\n",
       " ('사랑', 'Noun'),\n",
       " ('은', 'Josa'),\n",
       " ('눈물', 'Noun'),\n",
       " ('의', 'Josa'),\n",
       " ('씨앗', 'Noun'),\n",
       " ('/', 'Punctuation'),\n",
       " ('정동원', 'Noun'),\n",
       " ('-', 'Punctuation'),\n",
       " ('눈물', 'Noun'),\n",
       " ('비', 'Noun'),\n",
       " ('/', 'Punctuation'),\n",
       " ('정동원', 'Noun'),\n",
       " ('-', 'Punctuation'),\n",
       " ('청춘', 'Noun'),\n",
       " ('/', 'Punctuation'),\n",
       " ('정동원', 'Noun'),\n",
       " ('-', 'Punctuation'),\n",
       " ('우수', 'Noun'),\n",
       " ('/', 'Punctuation'),\n",
       " ('정동원', 'Noun'),\n",
       " ('-', 'Punctuation'),\n",
       " ('누가', 'Noun'),\n",
       " ('울다', 'Verb')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt.pos(sample_text, norm =True , stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer2(text):\n",
    "    taglist = ['Adjective', 'Verb']\n",
    "    result_words = [word for (word,tag) in okt.pos(text,norm =True , stem=True) if tag in taglist]\n",
    "    return result_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['나서다'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=tokenizer2 , stop_words = stopwordlist)\n",
    "X_matrix = vectorizer.fit_transform(text_vectors)\n",
    "word_list= vectorizer.get_feature_names()\n",
    "document_term_matrix = pd.DataFrame(X_matrix.toarray(), columns=word_list)\n",
    "document_term_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
